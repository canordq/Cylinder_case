{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env3D_MARL\n",
    "### Main script, main function\n",
    "Environment class used in for making \"environment_base\" as seen in PARALLEL_3D_MARL, CONTINUE_PARALLEL_3D_MARL and DETERMINISTIC_3D_MARL\n",
    "50% of this file is saving rewards and ordering -> putting things in a form which TensorForce needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "multi- agent VERSION 18/04/2024 \n",
    "\n",
    "AUTHORS ->  POL\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "###-----------------------------------------------------------------------------\n",
    "## Import section\n",
    "\n",
    "## IMPORT PYTHON LIBRARIES\n",
    "import os, csv, numpy as np\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# IMPORT TENSORFLOW \n",
    "from tensorforce.environments import Environment\n",
    "\n",
    "# IMPORT INTERNAL LIBRARIES\n",
    "from configuration    import ALYA_BIN, ALYA_GMSH, ALYA_SETS, ALYA_CLEAN, OVERSUBSCRIBE, DEBUG\n",
    "from parameters       import bool_restart, neighbor_state, actions_per_inv, nb_inv_per_CFD, nz_Qs, mem_per_srun, dimension, case, simulation_params, num_nodes_srun, reward_function, jets, optimization_params, output_params, nb_proc, nb_actuations, nb_actuations_deterministic\n",
    "from env_utils        import run_subprocess, printDebug\n",
    "from alya             import write_case_file, write_witness_file, write_physical_properties, write_time_interval, write_run_type, detect_last_timeinterval\n",
    "from extract_forces   import compute_avg_lift_drag\n",
    "from witness          import read_last_wit\n",
    "from cr               import cr_start, cr_stop\n",
    "#from wrapper3D        import Wrapper\n",
    "import copy as cp\n",
    "\n",
    "###-------------------------------------------------------------------------###\n",
    "###-------------------------------------------------------------------------###\n",
    "\n",
    "### Environment definition\n",
    "class Environment(Environment):\n",
    "    \n",
    "\n",
    "    ###---------------------------------------------------------------------###\n",
    "    ###---------------------------------------------------------------------###\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment initialization\n",
    "Important and done every time\n",
    "ENV.ID is important because something should be different to test different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Initialization of the environment\n",
    "    ## only one time in multienvironment\n",
    "    def __init__(self, simu_name, number_steps_execution=1, continue_training=False, deterministic=False, ENV_ID = [-1,-1],  host = '', node=None, check_id=False):\n",
    "             \n",
    "        cr_start('ENV.init',0)\n",
    "        \n",
    "        self.simu_name    = simu_name\n",
    "        self.case         = case\n",
    "        self.ENV_ID       = ENV_ID\n",
    "        self.host         = \"enviroment%d\" %self.ENV_ID[0]\n",
    "        self.nodelist         = node\n",
    "        #self.nodelist     = [n for n in node.split(',')]\n",
    "        self.do_baseline  = True # This parameter was being overwritten so it is no point to have it optional\n",
    "        self.action_count = 0\n",
    "        self.check_id     = check_id\n",
    "        self.dimension    = dimension\n",
    "        \n",
    "        self.number_steps_execution = number_steps_execution\n",
    "        self.reward_function        = reward_function\n",
    "        self.output_params          = output_params\n",
    "        self.optimization_params    = optimization_params\n",
    "        self.Jets                   = jets\n",
    "        self.n_jets                 = len(jets)\n",
    "        self.nz_Qs                  = nz_Qs\n",
    "        self.actions_per_inv        = actions_per_inv   \n",
    "        self.nb_inv_per_CFD         = nb_inv_per_CFD\n",
    "        self.bound_inv              = 6+self.ENV_ID[1]\n",
    "        self.neighbor_state         = neighbor_state\n",
    "\n",
    "        self.probes_values_global   = []     \n",
    "\n",
    "        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n",
    "        self.last_time            = round(self.simulation_timeframe[1],3)\n",
    "        self.delta_t_smooth       = simulation_params[\"delta_t_smooth\"]\n",
    "        self.smooth_func          = simulation_params[\"smooth_func\"]\n",
    "\n",
    "        self.previous_action_global = np.zeros(self.nb_inv_per_CFD)\n",
    "        self.action_global          = np.zeros(self.nb_inv_per_CFD)\n",
    "        \n",
    "        #postprocess values\n",
    "        self.history_parameters = {}\n",
    "        self.history_parameters[\"drag\"] = []\n",
    "        self.history_parameters[\"lift\"] = []\n",
    "        self.history_parameters[\"drag_GLOBAL\"] = []\n",
    "        self.history_parameters[\"lift_GLOBAL\"] = []\n",
    "        self.history_parameters[\"time\"] = []\n",
    "        self.history_parameters[\"episode_number\"] = []\n",
    "        name=\"output.csv\"\n",
    "        # if we start from other episode already done\n",
    "        last_row = None\n",
    "        if(os.path.exists(\"saved_models/\"+name)):\n",
    "            with open(\"saved_models/\"+name, 'r') as f:\n",
    "                for row in reversed(list(csv.reader(f, delimiter=\";\", lineterminator=\"\\n\"))):\n",
    "                    last_row = row\n",
    "                    break\n",
    "        if(not last_row is None):\n",
    "            self.episode_number = int(last_row[0])\n",
    "            self.last_episode_number = int(last_row[0])\n",
    "        else:\n",
    "            self.last_episode_number = 0\n",
    "            self.episode_number = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Episode drag/lift/global: not relevant in our channel case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        self.episode_drags = np.array([])\n",
    "        self.episode_lifts = np.array([])\n",
    "        self.episode_drags_GLOBAL = np.array([])\n",
    "        self.episode_lifts_GLOBAL = np.array([])\n",
    "        \n",
    "        self.continue_training = continue_training\n",
    "        self.deterministic     = deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic: because TensorForce doesn't know deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.deterministic: self.host = 'deterministic'\n",
    "\n",
    "        #check if the actual environment has to run cfd or not \n",
    "        # quick way --> if the 2nd component of the ENVID[] is 1...\n",
    "        \n",
    "        # Call parent class constructor\n",
    "        super().__init__()\n",
    "        \n",
    "        cr_stop('ENV.init',0)\n",
    "  \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continued training\n",
    "skip first computation (extend, append) (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   \n",
    "    def start(self):\n",
    "        cr_start('ENV.start',0)\n",
    "        # Get the new avg drag and lift and SAVE \n",
    "        temp_id = '{}'.format(self.host) if self.continue_training == True or self.deterministic == True else ''\n",
    "        \n",
    "        if self.continue_training:\n",
    "            average_drag, average_lift = 0., 0.\n",
    "            average_drag_GLOBAL, average_lift_GLOBAL = 0., 0.\n",
    "        else:\n",
    "            #average_drag, average_lift = compute_avg_lift_drag(self.episode_number, cpuid=temp_id)\n",
    "            average_drag, average_lift = compute_avg_lift_drag(self.episode_number, cpuid=temp_id, nb_inv=self.ENV_ID[1]) #NOTE: add invariant code! not the same BC\n",
    "            average_drag_GLOBAL, average_lift_GLOBAL = compute_avg_lift_drag(self.episode_number, cpuid=temp_id, nb_inv = self.nb_inv_per_CFD, global_rew = True) #NOTE: add invariant code! not the same BC\n",
    "\n",
    "        # Update history parameters\n",
    "        self.history_parameters[\"drag\"].extend([average_drag])\n",
    "        self.history_parameters[\"lift\"].extend([average_lift])\n",
    "        self.history_parameters[\"drag_GLOBAL\"].extend([average_drag_GLOBAL])\n",
    "        self.history_parameters[\"lift_GLOBAL\"].extend([average_lift_GLOBAL])\n",
    "        self.history_parameters[\"time\"].extend([self.last_time])        \n",
    "        self.history_parameters[\"episode_number\"].extend([self.episode_number])\n",
    "        self.save_history_parameters(nb_actuations)\n",
    "        print(\"Results : \\n\\tAverage drag : {}\\n\\tAverage lift : {}\".format(average_drag,average_lift))\n",
    "        \n",
    "        self.action = np.zeros(self.actions_per_inv*2)\n",
    "        \n",
    "        self.check_id = True # check if the folder with cpuid number is created\n",
    "        cr_stop('ENV.start',0)\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean\n",
    "clean everything to start from scratch; check to see if \"path.exists\" for the old data, and if it does, remove it\n",
    "Reset action count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def clean(self,full=False):\n",
    "        cr_start('ENV.clean',0)\n",
    "        if full:\n",
    "            # saved_models contains the .csv of all cd and cl agt the end of each episode\n",
    "            if os.path.exists(\"saved_models\"): run_subprocess('./','rm -rf','saved_models')\n",
    "            # Best model at the end of each episode\n",
    "            if os.path.exists(\"best_model\"): run_subprocess('./','rm -rf','best_model')\n",
    "        # si no hemos acabado el episodio, continuamos sumando actions\n",
    "        self.action_count = 1\n",
    "        cr_stop('ENV.clean',0)\n",
    "         \n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mesh\n",
    "don't need because we use gmesh (part of Alya)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def create_mesh(self):  # TODO: Flag para que no tenga que volver a hacer la malla\n",
    "        cr_start('ENV.mesh',0)\n",
    "        if self.do_baseline == True:\n",
    "            if self.dimension == 2:\n",
    "                 run_subprocess('gmsh','python3','geo_file_maker.py') # TODO: this should be a library and be called within this function\n",
    "                 run_subprocess('alya_files/case/mesh',ALYA_GMSH,'-2 %s'%self.case)\n",
    "            for jet in self.Jets.values(): jet.update_file('alya_files/case')       \n",
    "            write_witness_file('alya_files/case',output_params[\"locations\"])\n",
    "            run_subprocess('alya_files/case',ALYA_CLEAN,'')\n",
    "        cr_stop('ENV.mesh',0)\n",
    "        \n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "Just copy base case and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    def run_baseline(self,clean=True):\n",
    "        cr_start('ENV.run_baseline',0)\n",
    "        # Do a full clean\n",
    "        if clean: self.clean(True)\n",
    "        # Create the mesh\n",
    "        self.create_mesh()\n",
    "        # Setup alya files\n",
    "        run_subprocess('alya_files','cp -r','case baseline') # TODO: substitute for correct case   \n",
    "        #run_subprocess('alya_files/baseline/mesh','mv','*mpio.bin ..')\n",
    "        if self.dimension == 2: run_subprocess('alya_files/baseline','python3','initialCondition.py {0} 1. 0.'.format(self.case))\n",
    "        # Run alya\n",
    "        self.run(which='reset')\n",
    "        cr_stop('ENV.run_baseline',0)\n",
    "            \n",
    "    #-------------------------------------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 modes\n",
    "Reset mode: just starting; beginning of episode\n",
    "Execute: write case file loaded by Alya and checks all files; everything changes\n",
    "(probleM) Runtype: can you reset from previous start from Alya or delete?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #-------------------------------------------------------------------------------------------------------\n",
    "           \n",
    "    def run(self, which):\n",
    "        print(\"Simulation on : \", self.simulation_timeframe)\n",
    "        logssets = os.path.join('logs','log_sets.log')\n",
    "        if which == 'reset':\n",
    "            # Baseline run\n",
    "            if self.do_baseline == True: # necessary? better?\n",
    "                printDebug(\"\\n \\n Alya has started the baseline run! (Env2D-->run-->reset)\\n \\n\")\n",
    "                filepath = os.path.join('alya_files','baseline')\n",
    "                write_case_file(filepath,self.case,self.simu_name)\n",
    "                write_run_type(filepath,'NONCONTI',freq=1000)\n",
    "                write_time_interval(filepath,self.simulation_timeframe[0],self.simulation_timeframe[1])\n",
    "                write_physical_properties(filepath,simulation_params['rho'],simulation_params['mu'])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Alya\n",
    "Alya.bin is what runs Alya: need a lot of info to construct NPI\n",
    "    name of case, number of processors, memory per process (srun) IMPORTANT, nodes tot, host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Run Alya\n",
    "                casepath = os.path.join('alya_files','baseline')\n",
    "                logsrun  = os.path.join('logs','log_last_reset_run.log')\n",
    "                # Run subprocess\n",
    "                if self.dimension == 2 :\n",
    "                     run_subprocess(casepath,'mkdir -p','logs') # Create logs folder \n",
    "                     run_subprocess(casepath,ALYA_BIN,'%s'%self.case,nprocs=nb_proc,oversubscribe=OVERSUBSCRIBE,nodelist=self.nodelist,log=logsrun)#,parallel=True)\n",
    "                     run_subprocess(casepath,ALYA_SETS,'%s-boundary.nsi.set 3'%self.case,log=logssets) # TODO: Boundary hardcoded!!\n",
    "                if self.dimension == 3 :\n",
    "                     run_subprocess(casepath,'mkdir -p','logs',preprocess=True) # Create logs folder\n",
    "                     run_subprocess(casepath,ALYA_BIN,'%s'%self.case,nprocs=nb_proc,mem_per_srun=mem_per_srun,num_nodes_srun=num_nodes_srun,host=self.nodelist,log=logsrun)\n",
    "                     run_subprocess(casepath,ALYA_SETS,'%s-boundary.nsi.set 3'%self.case,log=logssets,preprocess=True)\n",
    "\n",
    "            self.do_baseline = False # Baseline done, no need to redo it       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute\n",
    "Copy 20 episodes, then need to run actions\n",
    "First action, then execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        elif which == 'execute':\n",
    "            # Actions run\n",
    "            printDebug(\"\\n \\n Alya has started executing an action! (Env3D-->run-->execute) \\n \\n\")\n",
    "            cr_start('ENV.run_actions',0)\n",
    "            filepath = os.path.join('alya_files','%s'%self.host,'%s' % self.ENV_ID[1],'EP_%d'%self.episode_number)\n",
    "\n",
    "            filepath_flag_sync = os.path.join('alya_files','%s'%self.host,'1','EP_%s'%self.episode_number,'flags_MARL')\n",
    "            action_end_flag_path  = os.path.join(filepath_flag_sync,'action_end_flag_%d' %self.action_count )\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            if self.ENV_ID[1] == 1:\n",
    "\n",
    "                write_run_type(filepath,'CONTI',freq=1000)\n",
    "                write_time_interval(filepath,self.simulation_timeframe[0],self.simulation_timeframe[1])\n",
    "                casepath = os.path.join('alya_files','%s'%self.host,'%s' %self.ENV_ID[1],'EP_%d'%self.episode_number)\n",
    "                logsrun  = os.path.join('logs','log_last_execute_run.log' if not DEBUG else 'log_execute_run_%d.log'%self.action_count)\n",
    "                # Run subprocess\n",
    "                if self.dimension == 2:\n",
    "                     run_subprocess(casepath,'mkdir -p','logs') # Create logs folder\n",
    "                     run_subprocess(casepath,ALYA_BIN,'%s'%self.case,nprocs=nb_proc,oversubscribe=OVERSUBSCRIBE,nodelist=self.nodelist,log=logsrun)#,parallel=True)\n",
    "                     run_subprocess(casepath,ALYA_SETS,'%s-boundary.nsi.set 3'%self.case,log=logssets) # TODO: Boundary hardcoded!!\n",
    "                if self.dimension == 3:\n",
    "                     run_subprocess(casepath,'mkdir -p','logs',preprocess=True) # Create logs folder\n",
    "                     run_subprocess(casepath,ALYA_BIN,'%s'%self.case,nprocs=nb_proc,mem_per_srun=mem_per_srun,num_nodes_srun=num_nodes_srun,host=self.nodelist,log=logsrun)\n",
    "                     run_subprocess(casepath,ALYA_SETS,'%s-boundary.nsi.set 3'%self.case,log=logssets,preprocess=True)\n",
    "                \n",
    "                # CREATE A FILE THAT WORKS AS FLAG TO THE OTHERS ENVS\n",
    "                run_subprocess(filepath_flag_sync,'mkdir ','action_end_flag_%d' %self.action_count) # Create dir? not so elegant I think\n",
    "\n",
    "            else:\n",
    "                count_wait = 1 \n",
    "                if not self.deterministic: \n",
    "                    while(not os.path.exists(action_end_flag_path) or not os.path.isdir(action_end_flag_path)):\n",
    "                        if count_wait % 1000 == 0: \n",
    "                            print(\"Inv: %s is waiting for the action #%s\" %(self.ENV_ID, self.action_count))\n",
    "                        time.sleep(0.05)\n",
    "                        count_wait += 1\n",
    "\n",
    "                time.sleep(1)\n",
    "                print(\"Actions in %s are sync\" %self.ENV_ID)\n",
    "                    \n",
    "\n",
    "        \n",
    "            cr_stop('ENV.run_actions',0)\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save history\n",
    "Just saving the file/data, to do arrays, plot, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #-----------------------------------------------------------------------------------------------------\n",
    "   \n",
    "    def save_history_parameters(self, nb_actuations, name=\"output.csv\"):\n",
    "        \n",
    "        cr_start('ENV.save_cd_cl',0)\n",
    "        \n",
    "        # Save at the end of every episodes\n",
    "        self.episode_drags = np.append(self.episode_drags, self.history_parameters[\"drag\"])\n",
    "        self.episode_lifts = np.append(self.episode_lifts, self.history_parameters[\"lift\"])\n",
    "        self.episode_drags_GLOBAL = np.append(self.episode_drags_GLOBAL, self.history_parameters[\"drag_GLOBAL\"])\n",
    "        self.episode_lifts_GLOBAL = np.append(self.episode_lifts_GLOBAL, self.history_parameters[\"lift_GLOBAL\"])\n",
    "        \n",
    "        if self.action_count == nb_actuations or self.episode_number == 0:\n",
    "            file = os.path.join('saved_models',name)\n",
    "\n",
    "            print(\"Action : saving history parameters in %s\"%file)\n",
    "            self.last_episode_number = self.episode_number\n",
    "            \n",
    "            avg_drag = np.mean(self.history_parameters[\"drag\"][-1:])\n",
    "            avg_lift = np.mean(self.history_parameters[\"lift\"][-1:])\n",
    "            avg_drag_GLOBAL = np.mean(self.history_parameters[\"drag_GLOBAL\"][-1:])\n",
    "            avg_lift_GLOBAL = np.mean(self.history_parameters[\"lift_GLOBAL\"][-1:])\n",
    "            \n",
    "            os.makedirs('saved_models',exist_ok=True)\n",
    "            if not os.path.exists(\"saved_models/\"+name):\n",
    "                with open(file,\"w\") as csv_file:\n",
    "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                    spam_writer.writerow([\"Episode\", \"AvgDrag\", \"AvgLift\", \"AvgDrag_GLOBAL\", \"AvgLift_GLOBAL\" ])\n",
    "                    spam_writer.writerow([self.last_episode_number, avg_drag, avg_lift, avg_drag_GLOBAL, avg_lift_GLOBAL])\n",
    "            else:\n",
    "                with open(file, \"a\") as csv_file:\n",
    "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                    spam_writer.writerow([self.last_episode_number, avg_drag, avg_lift, avg_drag_GLOBAL, avg_lift_GLOBAL])\n",
    "            self.episode_drags = np.array([])\n",
    "            self.episode_lifts = np.array([])\n",
    "            self.episode_drags_GLOBAL = np.array([])\n",
    "            self.episode_lifts_GLOBAL = np.array([])\n",
    "            \n",
    "            # Writes all the cl and cd in .csv\n",
    "            # IS THIS NECESSARY? I THINK WE DO NOT USE THE BEST MODEL\n",
    "            if os.path.exists(file):\n",
    "                run_subprocess('./','cp -r','saved_models best_model')\n",
    "            else:\n",
    "                if(os.path.exists(\"saved_models/output.csv\")):\n",
    "                    if(not os.path.exists(\"best_model\")):\n",
    "                        shutil.copytree(\"saved_models\", \"best_model\")\n",
    "                    else:\n",
    "                        best_file = os.path.join('best_model',name)\n",
    "                        last_iter = np.genfromtxt(file,skip_header=1,delimiter=';')[-1,1]\n",
    "                        best_iter = np.genfromtxt(best_file,skip_header=1,delimiter=';')[-1,1]\n",
    "                        if float(best_iter) < float(last_iter):\n",
    "                            print(\"best_model updated\")\n",
    "                            run_subprocess('./','rm -rf','best_model')\n",
    "                            run_subprocess('./','cp -r','saved_models best_model')\n",
    "            printDebug(\"\\n \\n Saving parameters, AVG DRAG & AVG LIFT, which are the input of the neural network! (Env2D-->execute-->save_history_parameters)\\n \\n\")\n",
    "            print(\"Done.\")\n",
    "        cr_stop('ENV.save_cd_cl',0)\n",
    "        \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    def save_this_action(self):\n",
    "        \n",
    "        cr_start('ENV.save_action',0)\n",
    "    \n",
    "        print(\"Saving a new action : N°\",self.action_count)\n",
    "        \n",
    "        name_a = \"output_actions.csv\"\n",
    "        if(not os.path.exists(\"actions\")):\n",
    "            os.mkdir(\"actions\")\n",
    "        \n",
    "        if(not os.path.exists(\"actions/{}\".format(self.host))):\n",
    "            os.mkdir(\"actions/{}\".format(self.host))\n",
    "        \n",
    "        if(not os.path.exists(\"actions/{}/{}_{}\".format(self.host,self.ENV_ID[0],self.ENV_ID[1]))):\n",
    "            os.mkdir(\"actions/{}/{}_{}\".format(self.host,self.ENV_ID[0],self.ENV_ID[1]))\n",
    "        \n",
    "        if(not os.path.exists(\"actions/{}/{}_{}/ep_{}/\".format(self.host, self.ENV_ID[0], self.ENV_ID[1], self.episode_number))):\n",
    "            os.mkdir(\"actions/{}/{}_{}/ep_{}/\".format(self.host, self.ENV_ID[0],self.ENV_ID[1], self.episode_number))\n",
    "        \n",
    "        path_a = \"actions/{}/{}_{}/ep_{}/\".format(self.host,self.ENV_ID[0],self.ENV_ID[1],self.episode_number)\n",
    "        \n",
    "        action_line = \"{}\".format(self.action_count)\n",
    "        for i in range(self.actions_per_inv):\n",
    "            action_line = action_line + \"; {}\".format(self.action[i])\n",
    "        \n",
    "        if(not os.path.exists(path_a+name_a)):\n",
    "            header_line = \"Action\"\n",
    "            for i in range(self.actions_per_inv):\n",
    "                header_line = header_line + \"; Jet_{}\".format(i+1)\n",
    "                \n",
    "            with open(path_a+name_a, \"w\") as csv_file:\n",
    "                spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n",
    "                spam_writer.writerow([header_line])\n",
    "                spam_writer.writerow([action_line])\n",
    "        else:\n",
    "            with open(path_a+name_a, \"a\") as csv_file:\n",
    "                spam_writer=csv.writer(csv_file, lineterminator=\"\\n\")\n",
    "                spam_writer.writerow([action_line])\n",
    " \n",
    "        \n",
    "        print(\"Done.\")\n",
    "        \n",
    "        cr_stop('ENV.save_action',0)\n",
    "\n",
    "            \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewards\n",
    "Note: common problem: reward not properly scaled or not capturing fluxuations at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    def save_reward(self,reward):\n",
    "        \n",
    "        cr_start('ENV.save_reward',0)\n",
    "    \n",
    "        print(\"Saving a new reward: N°\", reward)\n",
    "        \n",
    "        name_a = \"output_rewards.csv\"\n",
    "        \n",
    "        if(not os.path.exists(\"rewards\")):\n",
    "            os.mkdir(\"rewards\")\n",
    "\n",
    "        if(not os.path.exists(\"rewards/{}\".format(self.host))):\n",
    "            os.mkdir(\"rewards/{}\".format(self.host))\n",
    "            \n",
    "        if(not os.path.exists(\"rewards/{}/{}_{}\".format(self.host,self.ENV_ID[0],self.ENV_ID[1]))):\n",
    "            os.mkdir(\"rewards/{}/{}_{}\".format(self.host,self.ENV_ID[0],self.ENV_ID[1]))\n",
    "            \n",
    "        if(not os.path.exists(\"rewards/{}/{}_{}/ep_{}/\".format(self.host, self.ENV_ID[0], self.ENV_ID[1], self.episode_number))):\n",
    "            os.mkdir(\"rewards/{}/{}_{}/ep_{}/\".format(self.host, self.ENV_ID[0], self.ENV_ID[1], self.episode_number))\n",
    "            \n",
    "        path_a = \"rewards/{}/{}_{}/ep_{}/\".format(self.host, self.ENV_ID[0], self.ENV_ID[1], self.episode_number)\n",
    "        \n",
    "        if(not os.path.exists(path_a+name_a)):\n",
    "                with open(path_a+name_a, \"w\") as csv_file:\n",
    "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                    spam_writer.writerow([\"Action\", \"Reward\"])#, \"AvgRecircArea\"])\n",
    "                    spam_writer.writerow([self.action_count, reward])\n",
    "        else:\n",
    "                with open(path_a+name_a, \"a\") as csv_file:\n",
    "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                    spam_writer.writerow([self.action_count, reward])\n",
    "                \n",
    "        \n",
    "        print(\"Done.\")\n",
    "        \n",
    "        cr_stop('ENV.save_reward',0)\n",
    "        \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final reward\n",
    "Have whole episode, see accumulated reward for every episode (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    def save_final_reward(self,reward):\n",
    "    \n",
    "        print(\"Saving the last reward from episode {}: \".format(self.episode_number), reward)\n",
    "     \n",
    "        name_a = \"output_final_rewards.csv\"\n",
    "        \n",
    "        if(not os.path.exists(\"final_rewards\")):\n",
    "            os.mkdir(\"final_rewards\")\n",
    "\n",
    "        if(not os.path.exists(\"final_rewards/{}\".format(self.host))):\n",
    "            os.mkdir(\"final_rewards/{}\".format(self.host))\n",
    "            \n",
    "        if(not os.path.exists(\"final_rewards/{}/{}_{}\".format(self.host,self.ENV_ID[0],self.ENV_ID[1]))):\n",
    "            os.mkdir(\"final_rewards/{}/{}_{}\".format(self.host,self.ENV_ID[0],self.ENV_ID[1]))\n",
    "            \n",
    "        path_a = \"final_rewards/{}/{}_{}/\".format(self.host,self.ENV_ID[0],self.ENV_ID[1])\n",
    "        \n",
    "        if(not os.path.exists(path_a+name_a)):\n",
    "            with open(path_a+name_a, \"w\") as csv_file:\n",
    "                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                spam_writer.writerow([\"EPISODE\", \"REWARD\"])#, \"AvgRecircArea\"])\n",
    "                spam_writer.writerow([self.episode_number, reward])\n",
    "        else:\n",
    "            with open(path_a+name_a, \"a\") as csv_file:\n",
    "                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                spam_writer.writerow([self.episode_number, reward])\n",
    " \n",
    "        print(\"Done.\")\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful for scaling (?) idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #-----------------------------------------------------------------------------------------------------\n",
    "        \n",
    "    def save_comms_probes(self): #TODO: This function is not used. May be eliminated\n",
    "    \n",
    "        print(\"Saving probes inputs: N°\", self.action_count)\n",
    "     \n",
    "        name_a = \"output_probes_comms.csv\"\n",
    "        \n",
    "        if(not os.path.exists(\"probes_comms\")):\n",
    "            os.mkdir(\"probes_comms\")\n",
    "            \n",
    "        if(not os.path.exists(\"probes_comms/ep_{}/\".format(self.episode_number))):\n",
    "            os.mkdir(\"probes_comms/ep_{}/\".format(self.episode_number))\n",
    "            \n",
    "        path_a = \"probes_comms/ep_{}/\".format(self.episode_number)\n",
    "        \n",
    "        if(not os.path.exists(path_a+name_a)):\n",
    "                with open(path_a+name_a, \"w\") as csv_file:\n",
    "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                    array_acts = np.linspace(1, 24, dtype=int) \n",
    "                    spam_writer.writerow([\"Action\", array_acts])#, \"AvgRecircArea\"])\n",
    "                    spam_writer.writerow([self.action_count, self.probes_values])\n",
    "        else:\n",
    "                with open(path_a+name_a, \"a\") as csv_file:\n",
    "                    spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                    spam_writer.writerow([self.action_count, self.probes_values])\n",
    " \n",
    "        print(\"Done.\")\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recover start\n",
    "Every time we start an episode, recover baseline\n",
    "(still being debugged, some issues with restarting so we are forcing residual/continuous learning, uncontrolled to controlled state transition not enough. Therefore we are forcing to act like two episodes are one, go to second episode without restarting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #-----------------------------------------------------------------------------------------------------        \n",
    "       \n",
    "    ### AQUI DEBEMOS ANULAR EL RECUPERAR EL BASELINE SI YA EXISTE EL QUE TOCA\n",
    "    def recover_start(self):\n",
    "\n",
    "        cr_start('ENV.recover_start',0)\n",
    "\n",
    "        runpath = 'alya_files'\n",
    "\n",
    "        # flag to sync the cp times... then the other pseudo can read properly witness\n",
    "        # path example: /alya_files/environment1/1/EP_1/.\n",
    "        filepath_flag_sync_cp = os.path.join(runpath,'%s'%self.host,'1','EP_%d'%self.episode_number)\n",
    "\n",
    "        #lowcost mode --> CLEAN everytime olderfiles\n",
    "\n",
    "        #TODO --> check the rm if we need to restart from the last episode! \n",
    "        # TODO --> bool_restart_prevEP HAS TO BE 80-20 but not in parameters\n",
    "\n",
    "        if not DEBUG and self.episode_number>0:\n",
    "            if not self.bool_restart_prevEP:\n",
    "                runbin  = 'rm -rf'            \n",
    "                runargs = os.path.join('%s'%self.host,'%s'%self.ENV_ID[1],'EP_*')\n",
    "                #avoid checks in deterministic\n",
    "                if self.deterministic == False: run_subprocess(runpath,runbin,runargs)\n",
    "\n",
    "        if self.bool_restart_prevEP and self.episode_number>1:\n",
    "            runbin  = 'mv'\n",
    "            #runargs = '%s %s' %(os.path.join('%s'%self.host,'%s'%self.ENV_ID[1],'EP_*'),os.path.join('%s'%self.host,'%s'%self.ENV_ID[1],'EP_%d'%self.episode_number))\n",
    "        else:\n",
    "            runbin  = 'cp -r'\n",
    "            runargs = 'baseline %s' %os.path.join('%s'%self.host,'%s'%self.ENV_ID[1],'EP_%d'%self.episode_number)\n",
    "            logs    = os.path.join('baseline','logs','log_restore_last_episode_%d.log'%self.episode_number)\n",
    "            run_subprocess(runpath,runbin,runargs,log=logs)\n",
    "\n",
    "        run_subprocess(filepath_flag_sync_cp,'mkdir','flags_MARL') # Create dir? not so elegant I think\n",
    "        run_subprocess(os.path.join(filepath_flag_sync_cp,'flags_MARL'),'mkdir','action_end_flag_cp') # Create dir? not so elegant I think\n",
    "\n",
    "        cr_stop('ENV.recover_start',0)\n",
    "    \n",
    "    #--------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cpu_ID\n",
    "Create all folders to update\n",
    "good to see t.ex if you have 4 nodes, check to make sure you have 4 environments, not 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    # create folder for each cpu id in parallel and folder per invariants inside\n",
    "    def create_cpuID(self):\n",
    "        runpath = 'alya_files'\n",
    "        runbin  = 'mkdir -p'\n",
    "        #if self.deterministic == False:\n",
    "        runargs = '%s' %self.host\n",
    "        runpath2 = 'alya_files/%s' %self.host\n",
    "        run_subprocess(runpath,runbin,runargs)\n",
    "\n",
    "        for inv_i in range(1,self.nz_Qs+1):\n",
    "            runargs2 = '%s' %inv_i            \n",
    "            run_subprocess(runpath2,runbin,runargs2)\n",
    "            \n",
    "        # Write the nodes running this environmment\n",
    "        name = \"nodes\"\n",
    "        if(not os.path.exists(\"alya_files/{}/{}/\".format(self.host, self.ENV_ID[1])+name)):\n",
    "            with open(\"alya_files/{}/{}/\".format(self.host, self.ENV_ID[1])+name, \"w\") as csv_file:\n",
    "                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                spam_writer.writerow([\"Nodes in this learning\"])\n",
    "                spam_writer.writerow(self.nodelist)\n",
    "        else:\n",
    "            with open(\"alya_files/{}/{}/\".format(self.host,self.ENV_ID[1])+name, \"a\") as csv_file:\n",
    "                spam_writer=csv.writer(csv_file, delimiter=\";\", lineterminator=\"\\n\")\n",
    "                spam_writer.writerow([\"Nodes in this learning\"])\n",
    "                spam_writer.writerow(self.nodelist)\n",
    "        #else:\n",
    "        #    runargs = 'deterministic'\n",
    "        #    run_subprocess(runpath,runbin,runargs,check_return=False)\n",
    "            \n",
    "        print('Folder created for CPU ID: %s/%s' % (self.host,self.ENV_ID[1]))\n",
    "   \n",
    "             \n",
    "    # Optional\n",
    "    def close(self):\n",
    "        super().close()\n",
    "\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of observations\n",
    "POOOOL debugging\n",
    "\n",
    "probes_values_2: from global array, read depending on agent, the criteria from one position to another. The same is used repeatedly (becuase global). Done in parallel. There are many issues due to the syncronization (problems with cell being located in first column vs second, etc). \n",
    "### \"Halo\"\n",
    "In the cylinder case we are looking at neighbors. In our simulation, not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #-----------------------------------------------------------------------------------------------------\n",
    "    ## Default function required for the DRL\n",
    "\n",
    "    def list_observation(self):\n",
    "\n",
    "        if not self.neighbor_state:\n",
    "            #TODO: filter this observation state to each invariant and its neighbours: \n",
    "            batch_size_probes = int(len(self.probes_values_global)/self.nb_inv_per_CFD)\n",
    "            probes_values_2 = self.probes_values_global[((self.ENV_ID[1]-1)*batch_size_probes):(self.ENV_ID[1]*batch_size_probes)]\n",
    "        \n",
    "        else:\n",
    "            #TODO: filter this observation state to each invariant and its neighbours: \n",
    "            batch_size_probes = int(len(self.probes_values_global)/self.nb_inv_per_CFD)\n",
    "        \n",
    "            if self.ENV_ID[1] == 1:\n",
    "                probes_values_halo  = self.probes_values_global[((self.nb_inv_per_CFD-1)*batch_size_probes):(self.nb_inv_per_CFD*batch_size_probes)]\n",
    "                probes_values       = self.probes_values_global[((self.ENV_ID[1]-1)*batch_size_probes):((self.ENV_ID[1]+1)*batch_size_probes)]\n",
    "                probes_values_2     = np.concatenate((probes_values_halo, probes_values))\n",
    "                #print(\"POOOOOOOL len() line656:\", probes_values_2)\n",
    "                print(\"POOOOOOOL len() line657:\", len(probes_values_2))\n",
    "                print(\"POOOOOOOOOOOOOOOOL ---> TYPE PROBES \", type(probes_values_2))\n",
    "\n",
    "            elif self.ENV_ID[1] == self.nb_inv_per_CFD:\n",
    "                probes_values      = self.probes_values_global[((self.ENV_ID[1]-2)*batch_size_probes):(self.ENV_ID[1]*batch_size_probes)]\n",
    "                probes_values_halo = self.probes_values_global[0:batch_size_probes]\n",
    "                probes_values_2    = np.concatenate((probes_values, probes_values_halo))\n",
    "                #print(\"POOOOOOOL len() line664:\", probes_values_2)\n",
    "                print(\"POOOOOOOL len() line665:\", len(probes_values_2))\n",
    "                print(\"POOOOOOOOOOOOOOOOL ---> TYPE PROBES \", type(probes_values_2))\n",
    "\n",
    "            else:\n",
    "                probes_values_2    = self.probes_values_global[((self.ENV_ID[1]-2)*batch_size_probes):((self.ENV_ID[1]+1)*batch_size_probes)]\n",
    "                #print(\"POOOOOOOL len() line669:\", probes_values_2)\n",
    "                print(\"POOOOOOOL len() line670:\", len(probes_values_2))\n",
    "                print(\"POOOOOOOOOOOOOOOOL ---> TYPE PROBES \", type(probes_values_2))\n",
    "\n",
    "        return probes_values_2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States\n",
    "Already a template (doesnt need to be here (?) ) \n",
    "State function defines size of observing state\n",
    "locations, nr variants per CFD\n",
    "many witness, but state will be a coarse presentation\n",
    "Array of values\n",
    "### Important: must be integral, float, so it's in the same double (maybe?) form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    def states(self):\n",
    "\n",
    "        if not self.neighbor_state: \n",
    "            state_size = int(len(self.output_params[\"locations\"])/self.nb_inv_per_CFD)\n",
    "        else: \n",
    "            # TODO: introduce neighbours in parameters!\n",
    "            # NOW IS JUST 1 EACH SIDE 85*3\n",
    "            state_size = int(len(self.output_params[\"locations\"])/self.nb_inv_per_CFD)*(3)\n",
    "\n",
    "        return dict(type='float',\n",
    "                    shape=(state_size, )\n",
    "                    )\n",
    "            \n",
    "   #-----------------------------------------------------------------------------------------------------\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions\n",
    "In same way \n",
    "Define dictionay, type float, and shape (how many actions per invariant) (cylinder has 1, but in physical it's 2, but it's a copy so you only fix one)\n",
    "### Important! Min/max value: the framework needs to bound action space\n",
    "In parameters file we can increase if needed\n",
    "All actions from template from TensorForce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #-----------------------------------------------------------------------------------------------------    \n",
    "        \n",
    "    def actions(self):\n",
    "        \n",
    "        \"\"\"Action is a list of n_jets-1 capped values of Q\"\"\"\n",
    "        \"\"\"UPDATE --> now with multiple Q per jet slot --> use nz_Qs\"\"\"\n",
    "        \"\"\"UPDATE 2 --> NOW WITH MARL --> ACTIONS_PER_INV = 1\"\"\"\n",
    " \n",
    "        return dict(type='float',\n",
    "                    shape=(self.actions_per_inv), \n",
    "                           min_value=self.optimization_params[\"min_value_jet_MFR\"],\n",
    "                           max_value=self.optimization_params[\"max_value_jet_MFR\"]\n",
    "                    )\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset and execute\n",
    "First function you see when you start an episode\n",
    "CHECK_ID, ENV_ID checks that all of them are ready (safetys)\n",
    "Clean: calling funcion to reset after episode\n",
    "Boolean: (being debugged) self.bool_restart_prevEP = bool_restart\n",
    "Simulation timeframe: self.simulation_timeframe: boundary condition smoothing; linked to parameters (time interval in baseline)\n",
    "If in baseline 0-100, this needs to start at 100 and go one timestep further\n",
    "### Important! For the parts he's debugging, set them to \"false\" in parameters to go around them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "\n",
    "        if self.ENV_ID[1] != 1: time.sleep(4)\n",
    "\n",
    "        \"\"\"Reset state\"\"\"\n",
    "        print(\"\\n \\n Reset to initalize each episode (copy baseline, clean action count...)! (Env2D-->reset)\\n \\n\")\n",
    "        # Create a folder for each environment\n",
    "        print(\"POOOOL --> CHECK_ID = \", self.check_id)\n",
    "        print(\"POOOOL --> ENV_ID   = \", self.ENV_ID[1])\n",
    "        if self.check_id == True and self.ENV_ID[1] == 1:\n",
    "            self.create_cpuID()\n",
    "            self.check_id = False\n",
    "        \n",
    "        # Clean\n",
    "        print(\"\\n\\nLocation: Reset\")\n",
    "        print(\"Action: start to set up the case, set the initial conditions and clean the action counter\")\n",
    "        self.clean(False)\n",
    "\n",
    "        # Advance in episode\n",
    "        self.episode_number += 1\n",
    "\n",
    "        self.bool_restart_prevEP = bool_restart\n",
    "        \n",
    "        # Apply new time frame\n",
    "        # TODO --> fix time interval detected in the time_interval.dat file\n",
    "        #     it has to read and detect self.simulation_timeframe[1] auto\n",
    "        self.simulation_timeframe = simulation_params[\"simulation_timeframe\"]\n",
    "        t1 = self.simulation_timeframe[0]\n",
    "        if self.bool_restart_prevEP and self.episode_number>1: \n",
    "            t2 = detect_last_timeinterval(os.path.join('alya_files','%s'%self.host,'1','EP_*','time_interval.dat'))\n",
    "            print('POOOOOOOL PATH:', os.path.join('alya_files','%s'%self.host,'1','EP_%d'%(self.episode_number),'time_interval.dat'))\n",
    "        else:\n",
    "            t2 = self.simulation_timeframe[1]\n",
    "        self.simulation_timeframe = [t1,t2]\n",
    "        print(\"The actual timeframe is between {} and {}: \".format(t1,t2))\n",
    "              \n",
    "               \n",
    "        # Copy the baseline in the environment directory  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self action count: if in first action, master of ceremonies, ENV_ID, if first, you are in corner, the coordinates start and don't want to copy multiple baselines, only copy one\n",
    "Time interval changes every new ENV_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "        if self.action_count == 1 and self.ENV_ID[1]==1 :\n",
    "            self.recover_start()\n",
    "        \n",
    "        if self.ENV_ID[1] == 1: \n",
    "            write_time_interval(os.path.join('alya_files','%s'%self.host,'%s'%self.ENV_ID[1],'EP_%d'%self.episode_number),t1,t2)\n",
    "\n",
    "        print(\"Actual episode: {}\".format(self.episode_number))\n",
    "        print(\"\\n\\Action: extract the probes\")\n",
    "        NWIT_TO_READ=1 # Read n timesteps from witness file from behind, last instant\n",
    "\n",
    "        # TODO: READ THE WITNESS OF EACH PSEUDOENV!\n",
    "        # cp witness.dat to avoid IO problems in disk?\n",
    "        # filename     = os.path.join('alya_files','%s'%self.host,'%s'%self.ENV_ID[1],'EP_%d'%self.episode_number,'%s.nsi.wit'%self.case)\n",
    "        filename     = os.path.join('alya_files','%s'%self.host, '1','EP_%d'%self.episode_number,'%s.nsi.wit'%self.case)\n",
    "        filepath_flag_sync_cp = os.path.join('alya_files','%s'%self.host,'1','EP_%d'%self.episode_number,'flags_MARL')\n",
    "        \n",
    "        action_end_flag_cp_path  = os.path.join(filepath_flag_sync_cp,'action_end_flag_cp')\n",
    "        \n",
    "        print(\"POOOOOOOL -> self.deterministic = \", self.deterministic)\n",
    "\n",
    "        if not self.deterministic:\n",
    "            while(not os.path.exists(action_end_flag_cp_path)):\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        # Read witness file from behind, last instant (FROM THE INVARIANT running [*,1])\n",
    "        NWIT_TO_READ         = 1\n",
    "        filename             = os.path.join('alya_files','%s'%self.host,'1','EP_%d'%self.episode_number,'%s.nsi.wit'%self.case)\n",
    "\n",
    "        #read witness file and extract the entire array list\n",
    "        self.probes_values_global = read_last_wit(filename,output_params[\"probe_type\"], self.optimization_params[\"norm_press\"],NWIT_TO_READ)\n",
    "\n",
    "        #filter probes per jet (corresponding to the ENV.ID[])\n",
    "        probes_values_2      = self.list_observation()\n",
    "\n",
    "        return probes_values_2\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute\n",
    "Don't need to reset things, just go on to next action\n",
    "Create actions, compute, run, change interval, go again (loop)\n",
    "Done by TensorForce\n",
    "### Important! Previous action, action needed to do smoothing! Need info about previous actions (if not it's just discrete) Need to save action\n",
    "Each psuedo-environment has one of these executes running --> This one has two, ours will have one (until we add a second set of jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #-----------------------------------------------------------------------------------------------------\n",
    "    def execute(self, actions):\n",
    "        \n",
    "        action = []\n",
    "        for i in range(self.actions_per_inv):\n",
    "            action.append(self.optimization_params[\"norm_Q\"]*actions[i])\n",
    "            action.append(-self.optimization_params[\"norm_Q\"]*actions[i])  # This is to ensure 0 mass flow rate in the jets\n",
    "        \n",
    "        #for i in range(self.actions_per_inv, self.actions_per_inv*2):\n",
    "            #action.append(-self.optimization_params[\"norm_Q\"]*actions[i-self.actions_per_inv])\n",
    "        \n",
    "\n",
    "        self.previous_action = self.action #save the older one to smooth the change\n",
    "        self.action = action #update the new to reach at the end of smooth\n",
    "\n",
    "        # Write the action\n",
    "        self.save_this_action()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New flux, because TensorForce already computed the action, because you are returning values in the reset\n",
    "run_subprocess: ENV_ID - this invariant for this action is ready (can be very specific)\n",
    "Then add time together -> shown in simulation timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        print('New flux computed for INV: %s  :\\n\\tQs : %s' %(self.ENV_ID, self.action))\n",
    "        \n",
    "        dir_name = os.path.join('alya_files','%s'%self.host,'1','EP_%s' %self.episode_number,'flags_MARL')\n",
    "        run_subprocess(dir_name,'mkdir','%d_inv_action_%d_ready' %(self.ENV_ID[1],self.action_count))\n",
    "     \n",
    "        self.last_time = self.simulation_timeframe[1]\n",
    "        t1 = round(self.last_time,3)\n",
    "        t2 = t1 + self.delta_t_smooth\n",
    "            \n",
    "        self.simulation_timeframe = [t1,t2]\n",
    "\n",
    "        if self.ENV_ID[1]==1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            cr_start('ENV.actions_MASTER_thread1',0)\n",
    "\n",
    "            # wait until all the action from the others pseudoenvs are available\n",
    "            all_actions_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sync -- wait until all are ready to update boundary conditions\n",
    "Have manifold of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            while not all_actions_ready:\n",
    "                # loop over directory names\n",
    "                for i in range(1, self.nb_inv_per_CFD):\n",
    "                    dir_name = os.path.join('alya_files','%s'%self.host,'1','EP_%s' %self.episode_number,'flags_MARL','%d_inv_action_%d_ready' %(i,self.action_count))\n",
    "                    all_actions_ready = True\n",
    "                    if not os.path.exists(dir_name):\n",
    "                        all_actions_ready = False\n",
    "                time.sleep(0.2)\n",
    "            \n",
    "            print(\"**************** ALL ACTIONS ARE READY TO UPDATE BC *****************\")\n",
    "            #run_subprocess(dir_name,'rm -rf ','*_inv_action_*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output actions and append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            ## NOW READY TO MERGE ACTIONS: \n",
    "            # append and reading file\n",
    "            # open the file for reading\n",
    "\n",
    "            for i in range(self.nb_inv_per_CFD):\n",
    "                path_action_file = \"actions/{}/{}_{}/ep_{}/output_actions.csv\".format(self.host,self.ENV_ID[0],i+1,self.episode_number)\n",
    "                with open(path_action_file, 'r') as file:\n",
    "                    # read the lines of the file into a list\n",
    "                    lines = csv.reader(file, delimiter=';')\n",
    "                    # skip the header row\n",
    "                    next(lines)\n",
    "                    # initialize a variable to store the last value\n",
    "                    last_action = None\n",
    "                    # read each row and extract the second value\n",
    "                    for row in lines:\n",
    "                        last_action = float(row[1].strip())\n",
    "\n",
    "                    #print(\"POOOOOOOOOOL -> last action : \", last_action)\n",
    "                    self.previous_action_global[i] = self.action_global[i]\n",
    "                    self.action_global[i] = last_action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writes time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            write_time_interval(os.path.join('alya_files','%s'%self.host,'%s'%self.ENV_ID[1],'EP_%d'%self.episode_number),t1,t2)\n",
    "        \n",
    "            simu_path = os.path.join('alya_files','%s'%self.host,'%s'%self.ENV_ID[1],'EP_%d'%self.episode_number)\n",
    "\n",
    "            if self.case == 'cylinder':\n",
    "\n",
    "                for ijet, jet in enumerate(self.Jets.values()): # Only need to loop on the values, i.e., Jet class\n",
    "                    # Q_pre, Q_new, time_start, select smoothing law of the action\n",
    "                    #print(\"POOOOOOL jet.update : \",self.previous_action_global,self.action_global,self.simulation_timeframe[0],self.smooth_func)\n",
    "                    jet.update(self.previous_action_global,self.action_global,self.simulation_timeframe[0],self.smooth_func)\n",
    "                    # Update the jet profile alya file\n",
    "                    jet.update_file(simu_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maybe look for this library to see smoothing, etc***\n",
    "Airfoil is just cylinder - just to update jets (update boundary conditions)\n",
    "This update is \"outside\"; in jets library we have updates; different functions we can add; call function, compute smoothing, and thats it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            elif self.case == 'airfoil':\n",
    "                for ijet, jet in enumerate(self.Jets.values()): # Only need to loop on the values, i.e., Jet class\n",
    "                    # Update jets for the given epoch\n",
    "                    if self.smooth_func == 'parabolic':\n",
    "                        self.slope_pre = jet.slope_new\n",
    "                    else:\n",
    "                        self.slope_pre = 0\n",
    "                    \n",
    "                    # Q_pre, Q_new, time_start\n",
    "                    jet.update(self.previous_action[ijet],self.action[ijet],self.simulation_timeframe[0])\n",
    "                    # Update the jet profile alya file\n",
    "                    jet.update_file(simu_path)\n",
    "\n",
    "            cr_stop('ENV.actions_MASTER_thread1',0)\n",
    "\n",
    "\n",
    "        \n",
    "        # Start an alya run\n",
    "        t0 = time.time()\n",
    "        print(\"\\n\\nLocation : Execute/SmoothControl\\nAction: start a run of Alya\")\n",
    "        self.run(which = 'execute')\n",
    "        print(\"Done. time elapsed : \", time.time() - t0)\n",
    "        \n",
    "        # Get the new avg drag and lift --> LOCAL\n",
    "        average_drag, average_lift = compute_avg_lift_drag(self.episode_number, cpuid = self.host, nb_inv=self.ENV_ID[1])\n",
    "        self.history_parameters[\"drag\"].extend([average_drag])\n",
    "        self.history_parameters[\"lift\"].extend([average_lift])\n",
    "        self.history_parameters[\"time\"].extend([self.last_time])\n",
    "        self.history_parameters[\"episode_number\"].extend([self.episode_number])\n",
    "        self.save_history_parameters(nb_actuations)\n",
    "\n",
    "        # Get the new avg drag and lift --> GLOBAL\n",
    "        average_drag_GLOBAL, average_lift_GLOBAL = compute_avg_lift_drag(self.episode_number, cpuid = self.host, nb_inv = self.nb_inv_per_CFD, global_rew = True)\n",
    "        self.history_parameters[\"drag_GLOBAL\"].extend([average_drag_GLOBAL])\n",
    "        self.history_parameters[\"lift_GLOBAL\"].extend([average_lift_GLOBAL])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing\n",
    "Compute reward (volume of Q-events for ours) and actuation list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Compute the reward\n",
    "        reward = self.compute_reward()\n",
    "        self.save_reward(reward)\n",
    "        print('reward: {}'.format(reward))\n",
    "        \n",
    "        print(\"The actual action is {} of {}\".format(self.action_count, nb_actuations))\n",
    "\n",
    "        self.action_count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If in deterministic, something changes\n",
    "Terminal: feeds through, everything finished. But in deterministic we may want to run further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.deterministic == False and self.action_count <= nb_actuations:\n",
    "            terminal = False  # Episode is not done for training\n",
    "        elif self.deterministic == True and self.action_count <= nb_actuations_deterministic:\n",
    "            terminal = False  # Episode is not done for deterministic\n",
    "        else:\n",
    "            terminal = True   # Episode is done\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute final reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # write the last rewards at each episode to see the improvement \n",
    "            self.save_final_reward(reward)\n",
    "            \n",
    "            print(\"Actual episode: {} is finished and saved\".format(self.episode_number))\n",
    "            print(\"Results : \\n\\tAverage drag : {}\\n\\tAverage lift : {}\".format(average_drag,average_lift))\n",
    "        \n",
    "        print(\"\\n\\Action : extract the probes\")\n",
    "\n",
    "        \n",
    "        # Read witness file from behind, last instant (FROM THE INVARIANT running [*,1])\n",
    "        NWIT_TO_READ=1\n",
    "        filename      = os.path.join('alya_files','%s'%self.host,'1','EP_%d'%self.episode_number,'%s.nsi.wit'%self.case)\n",
    "        \n",
    "        #read witness file and extract the entire array list\n",
    "        self.probes_values_global = read_last_wit(filename,output_params[\"probe_type\"], self.optimization_params[\"norm_press\"],NWIT_TO_READ)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probe value 2 is second stage (least observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #filter probes per jet (corresponding to the ENV.ID[])\n",
    "        probes_values_2      = self.list_observation()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return\n",
    "When we are finishing, we want state, reward, terminal (final action) (are we done or not?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        return probes_values_2, terminal, reward\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing reward\n",
    "We have multiple rewards\n",
    "Just need to put in parameters\n",
    "### For Q-events: it can be deleted, and add if self.reward_function is minimize_total_volume...\n",
    "compute local reward, scales, osv\n",
    "(Pol is debugging this)\n",
    "Two components, local and global, weights to local and global and penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   def compute_reward(self):\n",
    "        # NOTE: reward should be computed over the whole number of iterations in each execute loop\n",
    "        if self.reward_function == 'plain_drag':  # a bit dangerous, may be injecting some momentum\n",
    "            values_drag_in_last_execute = self.history_parameters[\"drag\"][-1:]\n",
    "            return(np.mean(values_drag_in_last_execute) + 0.159)  # the 0.159 value is a proxy value corresponding to the mean drag when no control; may depend on the geometry\n",
    "        \n",
    "        elif self.reward_function == 'drag_plain_lift_2':  # a bit dangerous, may be injecting some momentum\n",
    "            avg_drag = np.mean(self.history_parameters[\"drag\"])\n",
    "            avg_lift = np.mean(self.history_parameters[\"lift\"])\n",
    "            return - avg_drag - 0.2 * abs(avg_lift)   \n",
    "        \n",
    "        elif self.reward_function == 'drag':  # a bit dangerous, may be injecting some momentum\n",
    "            return self.history_parameters[\"drag\"][-1] + 0.159\n",
    "       \n",
    "        elif self.reward_function == 'drag_plain_lift':  # a bit dangerous, may be injecting some momentum\n",
    "            ## get the last mean cd or cl value of the last Tk\n",
    "            avg_drag_2  = np.mean(self.history_parameters[\"drag\"][-1:])\n",
    "            avg_lift_2  = np.mean(self.history_parameters[\"lift\"][-1:])\n",
    "            avg_drag_2_global  = np.mean(self.history_parameters[\"drag_GLOBAL\"][-1:])\n",
    "            avg_lift_2_global  = np.mean(self.history_parameters[\"lift_GLOBAL\"][-1:])\n",
    "\n",
    "            reward_local  = (- avg_drag_2 - self.optimization_params[\"penal_cl\"] * abs(avg_lift_2) + self.optimization_params[\"offset_reward\"])\n",
    "            reward_global = (- avg_drag_2_global - self.optimization_params[\"penal_cl\"] * abs(avg_lift_2_global) + self.optimization_params[\"offset_reward\"])\n",
    "            print(\"POOOOOOOOL ---> reward_local: \", reward_local)\n",
    "            print(\"POOOOOOOOL ---> reward_global: \", reward_global)\n",
    "            print(\"POOOOOOOOL ---> cd_local: \", avg_drag_2)\n",
    "            print(\"POOOOOOOOL ---> cd_lift: \", avg_lift_2)\n",
    "            print(\"POOOOOOOOL ---> cd_local: \", avg_drag_2_global)\n",
    "            print(\"POOOOOOOOL ---> cd_lift: \", avg_lift_2_global)\n",
    "\n",
    "            alpha_rew     = self.optimization_params[\"alpha_rew\"]\n",
    "            reward_total = self.optimization_params[\"norm_reward\"]*((alpha_rew)*reward_local + (1 - alpha_rew)*reward_global)\n",
    "            \n",
    "            ## le añadimos el offset de 3.21 para partir de reward nula y que solo vaya a (+)\n",
    "            return reward_total\n",
    "        \n",
    "        elif self.reward_function == 'max_plain_drag':  # a bit dangerous, may be injecting some momentum\n",
    "            values_drag_in_last_execute = self.history_parameters[\"drag\"][-1:]\n",
    "            return - (np.mean(values_drag_in_last_execute) + 0.159)\n",
    "        \n",
    "        elif self.reward_function == 'drag_avg_abs_lift':  # a bit dangerous, may be injecting some momentum\n",
    "            avg_abs_lift = np.absolute(self.history_parameters[\"lift\"][-1:])\n",
    "            avg_drag = self.history_parameters[\"drag\"][-1:]\n",
    "            return avg_drag + 0.159 - 0.2 * avg_abs_lift\n",
    "        \n",
    "        elif self.reward_function == 'lift_vs_drag':  # a bit dangerous, may be injecting some momentum\n",
    "            ## get the last mean cd or cl value of the last Tk\n",
    "            avg_lift = np.mean(self.history_parameters[\"lift\"][-1:])\n",
    "            avg_drag = np.mean(self.history_parameters[\"drag\"][-1:])\n",
    "            \n",
    "            return self.optimization_params[\"norm_reward\"]*(avg_lift/avg_drag + self.optimization_params[\"offset_reward\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
