{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PARALLEL_3D_MARL\n",
    "Trains the model\n",
    "- run baseline\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/env python\n",
    "#\n",
    "# DEEP REINFORCEMENT LEARNING WITH ALYA\n",
    "#\n",
    "# Parallel training launcher\n",
    "#\n",
    "# Pol Suarez, Francisco Alcantara\n",
    "# 21/02/2022\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import os, sys\n",
    "import copy as cp\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries (tensorforce) don't want to be too invasive in TensorForce; \n",
    "Agent receives state and reward from environment, runner manages stages of ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorforce.agents import Agent\n",
    "from tensorforce.execution import Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our own libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env_utils     import run_subprocess, generate_node_list, read_node_list\n",
    "from configuration import ALYA_ULTCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run_subprocess is defined by us; to work in terminal in background because Alya is Fortran and not python: it converts library from python to fortran and leaves it in the background\n",
    "Cannot go forwards if command is not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cleaner\n",
    "run_subprocess('./',ALYA_ULTCL,'',preprocess=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training case: calls parameters from parameters.py \"dictionary\" (high reynolds, airfoil, 2D/3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training case\n",
    "# Set up which case to run\n",
    "training_case = \"re3900_cylinder_3D_MARL\"  # cylinder_2D, airfoil_2D, cylinder_3D\n",
    "run_subprocess('./','rm -f','parameters.py',preprocess=True) # Ensure deleting old parameters\n",
    "run_subprocess('./','ln -s','parameters/parameters_{}.py parameters.py'.format(training_case),preprocess=True)\n",
    "run_subprocess('alya_files','cp -r','case_{} case'.format(training_case),preprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment (class) \n",
    "the main library for main function we need with a template from Tensorforce, several functions for Tensorforce and several adapted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Env3D_MARL import Environment\n",
    "from parameters import nb_inv_per_CFD, sync_episodes, batch_size, nb_actuations, num_episodes, num_servers, nb_proc, simu_name, run_baseline, nz_Qs \n",
    "from cr import cr_reset, cr_info, cr_report\n",
    "import time\n",
    "\n",
    "# Ensure the chronometer is reset (timer)\n",
    "cr_reset()\n",
    "\n",
    "## Run\n",
    "initial_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node generation\n",
    "this will adapt number of servers to run in parallel and how many cores per server, automatically to DARDEL when run, meant for SLURM (for supercomputers) -> will need to be changed to run on local computers (training will be done on DARDEL) \n",
    "### Need to change in parameters!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list of nodes\n",
    "# TODO --- ADD NUM_CFD (MARL)\n",
    "generate_node_list(num_servers=num_servers,num_cores_server=nb_proc) # TODO: check if this works in MN!\n",
    "#TODO: Update to local nodelists with num_servers\n",
    "\n",
    "# Read the list of nodes\n",
    "nodelist = read_node_list()\n",
    "\n",
    "#IMPORTANT: this environment base is needed to do the baseline, the main one\n",
    "environment_base = Environment(simu_name=simu_name, node=nodelist[0]) # Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base environment\n",
    "Here parameters are linked after ensuring the old parameters were deleted\n",
    "Never change anything here (it has been the same since the 2D days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_baseline: \n",
    "    run_subprocess('alya_files','rm -rf','baseline') # Ensure deleting old parameters\n",
    "    environment_base.run_baseline(True)\n",
    "\n",
    "network = [dict(type='dense', size=512), dict(type='dense', size=512)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "Agent is PPO: proximal policy optimization (used in OpenAI)\n",
    "- set environment\n",
    "- max_epidode_timestep (how many interactions do you want per episode?)\n",
    "- batch side: decide number of episodes per batch (and define batch, how many episodes?)\n",
    "- Learning rate, subsampling...don't change (if we wanted to change, we would do it in parameters)\n",
    "\n",
    "All changes should be made in \"parameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.create(\n",
    "    # Agent + Environment\n",
    "    agent='ppo', environment=environment_base, max_episode_timesteps=nb_actuations,\n",
    "    # TODO: nb_actuations could be specified by Environment.max_episode_timesteps() if it makes sense...\n",
    "    # Network\n",
    "    network=network,\n",
    "    # Optimization\n",
    "    batch_size=batch_size, learning_rate=1e-3, subsampling_fraction=0.2, multi_step=25,\n",
    "    # Reward estimation\n",
    "    likelihood_ratio_clipping=0.2, predict_terminal_values=True,\n",
    "    # TODO: gae_lambda=0.97 doesn't currently exist\n",
    "    # Critic\n",
    "    ## TODO -- memory ? \n",
    "    baseline=network,\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline optimizer\n",
    "dont change anything, just use \"adam\" with learning rate (ok?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    baseline_optimizer=dict(\n",
    "        type='multi_step', num_steps=5,\n",
    "        optimizer=dict(type='adam', learning_rate=1e-3)\n",
    "    ),\n",
    "    # Regularization\n",
    "    entropy_regularization=0.01,\n",
    "    #TODO -- change parallel interaction_> how many calls to NN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel interactions\n",
    "you can have multiple CFDS, but from agents POV: all pieces of the \"cake\" are their own separate interactions/loops\n",
    "nb_inv_per_CFD: Number of invariants per CFD varies \"psuedo environment\"\n",
    "(t.ex.: 3 environments with 4 agents each = 12 parallel interactions -> script needs to replicate \"pythons\" in parallel in manifold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    parallel_interactions=num_servers*nb_inv_per_CFD,\n",
    "    # TensorFlow etc\n",
    "    saver=dict(directory=os.path.join(os.getcwd(), 'saver_data'), frequency=1, max_checkpoints=1),#parallel_interactions=number_servers,\n",
    "    summarizer=dict(\n",
    "        directory='data/summaries',\n",
    "        # list of labels, or 'all'\n",
    "        summaries=['entropy', 'kl-divergence', 'loss', 'reward', 'update-norm']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "copy environments, so that each has an ID\n",
    "env_ID like agent nr\n",
    "code should be general\n",
    "for cylinder it was only 1D (jet distribution/environments) so only 1D was needed for ENV_ID\n",
    "Create for one environment, then make parallel environments\n",
    "nz_Qs: number of agents per CFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(environment, np):  # called 1 time in PARALLEL_TRAINING.py\n",
    "    # np:= number of the parallel environment. e.g. between [1,4] for 4 parallel CFDenvironments\n",
    "    # (ni, nj):= env_ID[1]:= 'position'/'ID-card' of the 'pseudo-parallel' invariant environment (a tuple in 3d, in which we have a grid of actuators. A scalar in 2D, in which we have a line of actuators)\n",
    "    # nb_inv_envs:= total number of 'pseudo-parallel' invariant environments. e.g. 10\n",
    "    ''' input: one of the parallel environments (np); output: a list of nb_inv_envs invariant environments identical to np. Their ID card: (np, ni)'''\n",
    "    list_inv_envs = []\n",
    "    for j in range(nz_Qs):\n",
    "        env = cp.copy(environment)\n",
    "        env.ENV_ID = [np, (j+1)]\n",
    "        env.host=\"environment{}\".format(np)\n",
    "        list_inv_envs.append(env)\n",
    "    return list_inv_envs\n",
    "\n",
    "### Here the array of environments is defined, will be n-1 host (the 1st one is MASTER) #TODO: assign more nodes to an environment:\n",
    "print('Here is the nodelist: ', nodelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up environment for \"PARALLEL_3D_MARL\"\n",
    "Many inputs: simulation name\n",
    "Multi processing, multi agent...need to call certain particians and there are different environments (channel)\n",
    "We will have only one environment for channel: we will adapt template. Node list zero should be defined and copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the array of environments is defined, will be n-1 host (the 1st one is MASTER) #TODO: assign more nodes to an environment\n",
    "parallel_environments = [Environment(simu_name=simu_name, ENV_ID=[i,0], host=\"environment{}\".format(i+1), node=nodelist[i+1]) for i in range(num_servers)]\n",
    "\n",
    "environments = [split(parallel_environments[i], i+1)[j] for i in range(num_servers) for j in range(nz_Qs)]\n",
    "\n",
    "for env in environments:\n",
    "    print('Verif : ID ', env.ENV_ID, env.host)\n",
    "\n",
    "time.sleep(1.0)\n",
    "\n",
    "#environments = [Environment(simu_name=simu_name, ENV_ID=i, host=\"environment{}\".format(i+1),node=nodelist[i+1]) for i in range(num_servers)]\n",
    "for e in environments: \n",
    "    e.start() \n",
    "    time.sleep(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runner arranges stages in ML (this starts the episodes)\n",
    "multiprocessing: \"open the Tensorforce pipe at the same time!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start all environments at the same time\n",
    "#TODO: needs a toy case for the start class a 'light' baseline for everyone which is useless\n",
    "runner = Runner(agent=agent, environments=environments, remote='multiprocessing')\n",
    "\n",
    "#now start the episodes and sync_episodes is very useful to update the DANN efficiently\n",
    "runner.run(num_episodes=num_episodes, sync_episodes=sync_episodes)\n",
    "runner.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n",
    "Never reaches this point, takes too long. Just run as long as you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all the model data in model-numpy format \n",
    "agent.save(directory=os.path.join(os.getcwd(),'model-numpy'), format='numpy', append='episodes')\n",
    "\n",
    "agent.close()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"DRL simulation :\\nStart at : {}.\\nEnd at {}\\nDone in : {}\".format(initial_time,end_time,end_time-initial_time))\n",
    "\n",
    "cr_info()\n",
    "cr_report('DRL_TRAINING.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
